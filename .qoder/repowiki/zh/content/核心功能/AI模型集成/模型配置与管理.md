# 模型配置与管理

<cite>
**本文档中引用的文件**
- [aimodel.py](file://backend/apps/system/api/aimodel.py)
- [ModelList.vue](file://frontend/src/views/system/model/ModelList.vue)
- [ai_model_schema.py](file://backend/apps/system/schemas/ai_model_schema.py)
- [model_factory.py](file://backend/apps/ai_model/model_factory.py)
- [system_model.py](file://backend/apps/system/models/system_model.py)
</cite>

## 目录
1. [简介](#简介)
2. [后端API功能详解](#后端api功能详解)
3. [前端用户交互流程](#前端用户交互流程)
4. [模型配置存储结构](#模型配置存储结构)
5. [配置示例](#配置示例)
6. [默认模型设置逻辑](#默认模型设置逻辑)

## 简介
本文档详细说明了SQLBot系统中AI模型配置与管理功能的实现机制。涵盖后端API接口、前端组件交互、配置存储结构及默认模型管理等核心功能，为开发者和系统管理员提供全面的技术参考。

## 后端API功能详解

### 模型增删改查接口
后端通过`aimodel.py`文件中的FastAPI路由实现了对AI模型的完整CRUD操作。`query`接口支持按名称关键字搜索模型，并按默认模型优先、名称和创建时间排序返回结果。`add_model`接口接收`AiModelCreator`对象，将配置列表序列化为JSON字符串后存储到数据库。`update_model`接口使用`sqlmodel_update`方法实现模型信息的更新。`delete_model`接口在删除前会检查是否为默认模型，防止系统失去默认配置。

**Section sources**
- [aimodel.py](file://backend/apps/system/api/aimodel.py#L70-L153)

### 默认模型设置
`set_default`接口负责设置指定ID的模型为系统默认模型。实现逻辑为：首先将所有现有模型的`default_model`字段设为False，然后将目标模型的该字段设为True并提交事务。此操作确保系统中始终有且仅有一个默认模型。

```mermaid
flowchart TD
Start([设置默认模型]) --> GetModel["获取目标模型"]
GetModel --> CheckExist["模型存在?"]
CheckExist --> |否| ThrowError["抛出异常"]
CheckExist --> |是| CheckDefault["已是默认?"]
CheckDefault --> |是| End([无需操作])
CheckDefault --> |否| UpdateAll["更新所有模型<br>default_model=False"]
UpdateAll --> SetTarget["设置目标模型<br>default_model=True"]
SetTarget --> Commit["提交事务"]
Commit --> End
ThrowError --> End
```

**Diagram sources**
- [aimodel.py](file://backend/apps/system/api/aimodel.py#L52-L68)

### 连通性测试功能
`check_llm`接口实现了模型连通性检测功能，采用流式响应机制。该接口创建一个异步生成器函数，通过`LLMFactory`创建LLM实例，并向模型发送测试查询"1+1=?"。响应以`application/x-ndjson`媒体类型流式传输，每个数据块包含内容或错误信息的JSON编码。

#### 流式响应机制
```mermaid
sequenceDiagram
participant 前端 as 前端
participant API as check_llm接口
participant 工厂 as LLMFactory
participant 模型 as LLM实例
前端->>API : POST /status
API->>工厂 : create_llm(config)
工厂-->>API : 返回LLM实例
API->>模型 : astream("1+1=?")
loop 流式响应
模型-->>API : 返回数据块
API->>API : 处理数据块
API-->>前端 : 发送JSON数据块
end
模型->>API : 流结束
API->>前端 : 关闭连接
alt 发生异常
API->>API : 捕获异常
API-->>前端 : 发送错误JSON
end
```

**Diagram sources**
- [aimodel.py](file://backend/apps/system/api/aimodel.py#L17-L41)
- [model_factory.py](file://backend/apps/ai_model/model_factory.py#L85-L105)

#### 错误处理策略
连通性测试具有完善的错误处理机制。当检测过程中发生异常时，系统会捕获异常，记录错误日志，并通过流式响应返回格式化的错误信息。错误消息通过国际化函数`trans`进行本地化处理，确保用户能理解错误原因。

```mermaid
flowchart TD
Start([开始连通性测试]) --> TryBlock["try块"]
TryBlock --> CreateConfig["创建LLMConfig"]
CreateConfig --> CreateInstance["创建LLM实例"]
CreateInstance --> StreamTest["流式发送测试查询"]
StreamTest --> SuccessEnd([成功完成])
TryBlock --> ExceptionPath["发生异常"]
ExceptionPath --> LogError["记录错误日志"]
LogError --> LocalizeError["本地化错误消息"]
LocalizeError --> SendError["发送错误响应"]
SendError --> End([结束])
```

**Diagram sources**
- [aimodel.py](file://backend/apps/system/api/aimodel.py#L17-L41)

## 前端用户交互流程

### 供应商模型选择
`ModelList.vue`组件实现了供应商模型的选择界面。组件通过`supplierList`导入供应商列表，并使用计算属性`modelListWithSearch`实现搜索过滤功能。用户点击模型卡片时，通过`emits('clickModel', item)`触发事件，将选中的模型信息传递给父组件。

```mermaid
flowchart TD
Start([组件加载]) --> ImportData["导入supplierList"]
ImportData --> RenderUI["渲染UI界面"]
RenderUI --> UserInput["用户输入搜索关键词"]
UserInput --> FilterList["过滤模型列表"]
FilterList --> UpdateDisplay["更新显示列表"]
UserClick["用户点击模型"] --> HandleClick["handleModelClick"]
HandleClick --> EmitEvent["触发clickModel事件"]
EmitEvent --> Parent["通知父组件"]
```

**Diagram sources**
- [ModelList.vue](file://frontend/src/views/system/model/ModelList.vue#L1-L99)

### 搜索过滤机制
搜索过滤功能基于Vue的计算属性实现。`modelListWithSearch`计算属性监听`keywords`变量的变化，当关键词不为空时，过滤`supplierList`中名称包含关键词的项目（不区分大小写）。若搜索结果为空，则显示"未找到相关内容"的空状态提示。

**Section sources**
- [ModelList.vue](file://frontend/src/views/system/model/ModelList.vue#L1-L99)

### 点击事件处理
点击事件处理流程如下：用户点击模型卡片触发`handleModelClick`方法，该方法接收被点击的模型对象作为参数，然后通过`emits`函数触发`clickModel`自定义事件，将模型数据传递给父组件进行后续处理。

```mermaid
flowchart LR
Click["用户点击模型卡片"] --> Handler["handleModelClick(item)"]
Handler --> Emit["emits('clickModel', item)"]
Emit --> Parent["父组件接收事件"]
Parent --> Process["处理模型选择"]
```

**Diagram sources**
- [ModelList.vue](file://frontend/src/views/system/model/ModelList.vue#L1-L99)

## 模型配置存储结构

### 配置字段JSON格式
模型配置信息存储在数据库的`config`字段中，采用JSON序列化格式。该字段存储一个对象数组，每个对象包含`key`、`val`和`name`三个属性，分别表示配置项的键名、值和显示名称。这种设计支持灵活的动态参数配置。

```mermaid
erDiagram
CONFIG_ITEM {
string key PK
object val
string name
}
CONFIG_ITEM ||--o{ MODEL : "belongs to"
```

**Diagram sources**
- [ai_model_schema.py](file://backend/apps/system/schemas/ai_model_schema.py#L1-L29)
- [system_model.py](file://backend/apps/system/models/system_model.py#L14-L21)

### 动态参数传递机制
`additional_params`机制实现了动态参数的传递。在创建`LLMConfig`时，系统遍历`config_list`，将每个配置项的键值对转换为字典。`prepare_model_arg`工具函数负责处理参数值的预处理，确保不同类型的数据能正确传递给LLM实例。

```mermaid
flowchart TD
Start([开始处理配置]) --> Loop["遍历config_list"]
Loop --> CheckKey["检查key和val存在"]
CheckKey --> |是| ProcessVal["prepare_model_arg(val)"]
ProcessVal --> AddToDict["添加到additional_params"]
AddToDict --> NextItem["下一个配置项"]
NextItem --> Loop
Loop --> |完成| CreateConfig["创建LLMConfig"]
CreateConfig --> End([返回配置对象])
CheckKey --> |否| SkipItem["跳过该项"]
SkipItem --> NextItem
```

**Diagram sources**
- [aimodel.py](file://backend/apps/system/api/aimodel.py#L17-L41)
- [model_factory.py](file://backend/apps/ai_model/model_factory.py#L17-L42)

## 配置示例

### OpenAI模型配置
OpenAI模型配置需要提供API密钥、基础URL和温度参数。示例如下：
- **API密钥**: `sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx`
- **基础URL**: `https://api.openai.com/v1`
- **温度参数**: `0.7`
- **其他参数**: 可通过`config`字段添加`max_tokens`、`top_p`等高级参数

**Section sources**
- [ai_model_schema.py](file://backend/apps/system/schemas/ai_model_schema.py#L1-L29)

### VLLM模型配置
VLLM模型配置与OpenAI类似，但协议类型不同。示例如下：
- **API密钥**: `Empty` (VLLM可能不需要或使用其他认证方式)
- **基础URL**: `http://vllm-server:8000/v1`
- **温度参数**: `0.8`
- **模型名称**: `llama-2-70b-chat`

**Section sources**
- [model_factory.py](file://backend/apps/ai_model/model_factory.py#L85-L105)

## 默认模型设置逻辑

### 自动设置逻辑
系统在创建第一个模型时会自动将其设为默认模型。`add_model`接口通过查询数据库中现有模型的数量，若数量为0，则将`default_model`字段设为True。这确保了系统初始化后立即拥有可用的默认配置。

```mermaid
flowchart TD
Start([添加新模型]) --> CountModels["查询模型总数"]
CountModels --> IsFirst["总数为0?"]
IsFirst --> |是| SetDefault["设置default_model=True"]
IsFirst --> |否| KeepDefault["保持default_model=False"]
SetDefault --> SaveModel["保存模型"]
KeepDefault --> SaveModel
SaveModel --> End([完成])
```

**Diagram sources**
- [aimodel.py](file://backend/apps/system/api/aimodel.py#L120-L130)

### 系统初始化处理
系统初始化时，`get_default_config`函数负责获取默认模型配置。该函数查询数据库中`default_model`为True的记录，若未找到则抛出异常。获取到模型后，解析其`config`字段中的附加参数，并构造`LLMConfig`对象返回，供系统其他组件使用。

```mermaid
flowchart TD
Start([获取默认配置]) --> QueryDB["查询默认模型"]
QueryDB --> Found["找到默认模型?"]
Found --> |否| ThrowException["抛出异常"]
Found --> |是| ParseConfig["解析config字段"]
ParseConfig --> CreateLLMConfig["创建LLMConfig对象"]
CreateLLMConfig --> ReturnConfig["返回配置"]
ThrowException --> End
ReturnConfig --> End
```

**Diagram sources**
- [model_factory.py](file://backend/apps/ai_model/model_factory.py#L120-L144)